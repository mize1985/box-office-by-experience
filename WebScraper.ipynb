{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_urls(table_url):\n",
    "    response = requests.get(table_url)\n",
    "    soup = BeautifulSoup(response.text, 'lxml')\n",
    "    links=soup.table.find_all(class_='a-link-normal')\n",
    "    #response.status_code\n",
    "    link_list=[]\n",
    "    for link in links:\n",
    "        link_url=link.get('href')\n",
    "        movie_check=re.compile('^(\\/title)')\n",
    "        if movie_check.match(link_url):\n",
    "            link_list.append('https://www.boxofficemojo.com/'+link_url[0:17:]+'credits/?ref_=bo_tt_tab#tabs')\n",
    "    return link_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_attributes(soup):\n",
    "    \"\"\"\n",
    "    Extracts all cast and crew information from a movie's Box Office Mojo page.\n",
    "    Takes text of an html response and returns a dictionary of information.\n",
    "    \"\"\"\n",
    "    \n",
    "    attributes={}\n",
    "    \n",
    "    # Get the Domestic Box Office Gross\n",
    "    domestic_strings = soup.find('div', {'class':'a-section a-spacing-none mojo-performance-summary-table'\n",
    "        }).find('span', {'class': 'money'}).contents[0][1::].split(',')\n",
    "    domestic_string = ''\n",
    "    for text in domestic_strings:\n",
    "        domestic_string += text\n",
    "    attributes['Domestic'] = int(domestic_string)\n",
    "    \n",
    "    \n",
    "    # Get normal attributes if available\n",
    "    main_table=soup.find('div', {'class':'a-section a-spacing-none mojo-summary-values mojo-hidden-from-mobile'\n",
    "        }).find_all('span')\n",
    "    for i,element in enumerate(main_table):\n",
    "        if len(element.contents) >= 1: # Not all fields are populated\n",
    "            if element.contents[0] == 'Domestic Distributor':\n",
    "                if len(main_table[i+1].contents) >= 1:\n",
    "                    attributes['Domestic Distributor'] = main_table[i+1].contents[0]\n",
    "            elif element.contents[0] == 'Budget':\n",
    "                if len(main_table[i+2].contents) >= 1:\n",
    "                    budget_strings = main_table[i+2].contents[0][1::].split(',')\n",
    "                    budget_string = ''\n",
    "                    for text in budget_strings:\n",
    "                        budget_string += text\n",
    "                    attributes['Budget'] = int(budget_string)\n",
    "            elif element.contents[0] == 'Earliest Release Date':\n",
    "                if len(main_table[i+1].contents) >= 1:\n",
    "                    attributes['Release Date'] = pd.to_datetime(main_table[i+1].contents[0].split('\\n')[0])\n",
    "            elif element.contents[0] == 'MPAA':\n",
    "                if len(main_table[i+1].contents) >= 1:\n",
    "                    attributes['MPAA'] = main_table[i+1].contents[0]\n",
    "            elif element.contents[0] =='Running Time':\n",
    "                # Convert string of hrs and mins to integer minutes\n",
    "                if len(main_table[i+1].contents) >= 1:\n",
    "                    time_strings = main_table[i+1].contents[0].split(' ')\n",
    "                    if len(time_strings) == 2:\n",
    "                        time_minutes = int(time_strings[0])*60\n",
    "                    elif len(time_strings) == 4:\n",
    "                        time_minutes = int(time_strings[0])*60+int(time_strings[2])\n",
    "                    else:\n",
    "                        time_minutes = np.nan()\n",
    "                    attributes['Length'] = time_minutes\n",
    "            elif element.contents[0] == 'Genres':\n",
    "                if len(main_table[i+1].contents) >= 1:\n",
    "                    genre_list = main_table[i+1].contents[0].split('\\n')[0::2]\n",
    "                    for genre in genre_list:\n",
    "                        attributes[genre.strip()] = 1\n",
    "    \n",
    "    role_counts = {}\n",
    "    # Get crew\n",
    "    crew_table_contents = soup.find('table', {'id': 'principalCrew'}).find_all('td')\n",
    "    for i,element in enumerate(crew_table_contents):\n",
    "        if i%2==0: name = str(element.a.contents[0])\n",
    "        else:\n",
    "            role = (element.contents[0])\n",
    "            if role not in role_counts.keys(): role_counts[role] = 0\n",
    "            role_counts[role] += 1\n",
    "            if role_counts[role] < 3: # up to 2 crew members of each type per movie\n",
    "                attribute = role + '_' + str(role_counts[role])\n",
    "                attributes[attribute] = name\n",
    "    #Get cast\n",
    "    cast_table_contents = soup.find('table', {'id': 'principalCast'}).find_all('a')\n",
    "    actor_count = 0\n",
    "    #Collect all actors for each movie individually\n",
    "    for element in cast_table_contents[0::2]:\n",
    "        actor_count += 1\n",
    "        attributes[('actor_'+str(actor_count))] = str(element.contents[0])\n",
    "    return attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First get the list of movie URLs\n",
    "\n",
    "initial_url='https://www.boxofficemojo.com/chart/top_lifetime_gross/?offset='\n",
    "expanded_url_list=[]\n",
    "#Next button only works for the first 1000, but we can go out of bounds\n",
    "for i in range (0,10200,200):\n",
    "    table_page = initial_url+str(i)\n",
    "    expanded_url_list+=extract_urls(table_page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then get the data from each movie URL\n",
    "\n",
    "sys.setrecursionlimit(5000)# had trouble with this for pickling once\n",
    "film_dictionary={}\n",
    "for batch_number in range (0,10000,2000):\n",
    "    for i,url in enumerate(expanded_url_list[batch_number:(batch_number+2000):]):\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.text, 'lxml')\n",
    "        try: # Some don't work\n",
    "            current_title = soup.find('title').contents[0].split(' - Box Office Mojo')[0]\n",
    "            # Account for re-makes\n",
    "            while current_title in film_dictionary.keys():\n",
    "                current_title+='_other'\n",
    "            print(batch_number+i+1,current_title)\n",
    "            film_dictionary[current_title] = get_attributes(soup)\n",
    "        except: #So move on\n",
    "            print((batch_number+i+1),' failed')\n",
    "            continue\n",
    "            \n",
    "#Pickle every 2000 movies just in case of crashes\n",
    "    with open((str(batch_number)+'new_films.pickle'), 'wb') as to_write:\n",
    "        pickle.dump(film_dictionary, to_write)\n",
    "    to_write.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
